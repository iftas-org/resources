IFTAS and the SW-ISAC use the following labels and definitions to label actors, behaviour, and content.

# Labels 

```
Account-Takeover
Astroturfing
Brigading
Catfishing
Content-and-Conduct-Related-Risk
Coordinated-Inauthentic-Behaviour
Copyright-Infringement
Counterfeit
Cross-Platform-Abuse
CSAM
CSEA
Defamation
Dehumanization
Disinformation
Doxxing
Explicit-Content
Farming
Glorification-of-Violence
Hate-Speech
Impersonation
Incitement
Misinformation
Abuse
NCII
Online-Harassment
Phishing
Service-Abuse
Sock-Puppets
Sextortion
Spam
Synthetic-Media
Troll
TVEC
Violent-Threat
```

# Definitions

## Account-Takeover
Where an unauthorized user gains control of a user account, through means such as hacking, phishing or buying leaked credentials.

## APT
Advanced Persistent Threat - APT actors are well-resourced and engage in sophisticated malicious cyber activity that is targeted and aimed at prolonged network/system intrusion. APT objectives could include espionage, data theft, and network/system disruption or destruction.

## Astroturfing
Organized activity intended to create the deceptive appearance of broad, authentic grassroots support or opposition to a given cause or organization, when in reality the activity is being motivated, funded or coordinated by a single or small number of obscured sources.

## Brigading
Coordinated, often pre-planned, mass online activity to affect a piece of content, or an account, or an entire community or message board. Examples include coordinated upvoting or downvoting a post to affect its distribution, mass-reporting an account (usually falsely) for abuse in an attempt to cause the service provider to suspend it, or inundating a business with good or bad reviews.

## Catfishing
Where someone creates a fake persona on an online service, such as social media or a dating application, and forms a relationship with someone who believes the persona to be real.

## Content- and Conduct-Related Risk
The possibility of certain illegal, dangerous, or otherwise harmful content or behavior, including risks to human rights, which are prohibited by relevant policies and terms of service.

## Coordinated-Inauthentic-Behaviour
Organized online activity where an account or groups of accounts including “fake” secondary accounts (which exist solely or mainly to engage in such campaigns) act to mislead people or fraudulently elevate the popularity or visibility of content or accounts, such as mass-following an account to raise its clout.

## Copyright-Infringement
The use of material that is protected by copyright law (such as text, image, or video) in a way that violates the rights of the copyright holder, without the rightsholder’s permission and without an applicable copyright exception or limitation.

## Counterfeit
The unauthorized manufacture or sale of merchandise or services with an inauthentic trademark, which may have the effect of deceiving consumers into believing they are authentic.

## Cross-Platform-Abuse
Where a bad actor or group will organize a campaign of abuse (such as harassment, trolling or disinformation) using multiple online services.

## CSAM
Child Sexual Abuse Material - Imagery or videos which show a person who is a child and engaged in or is depicted as being engaged in explicit sexual activity. 

### CG-CSAM
Optional label for Computer-Generated CSAM

### SG-CSAM
Optional label for Self-Generated CSAM

## CSEA
Child Sexual Exploitation and Abuse - A broad category that encompasses both material depicting child sexual abuse, other sexualised content depicting children, and includes grooming.

## Defamation
A legal claim based on asserting something about a person that is shared with others and which causes harm to the reputation of the statement’s subject (the legal elements and applicable defenses vary by jurisdiction).

## Dehumanization
Describing people in ways that deny or diminish their humanity, such as comparing a given group to insects, animals or diseases.

## Disinformation
False information that is spread intentionally and maliciously to create confusion, encourage distrust, and potentially undermine political and social institutions.

## Doxxing
The act of disclosing someone’s personal, non-public information — such as a real name, home address, phone number or any other data that could be used to identify the individual — in an online forum or other public place without the person’s consent.

## Explicit-Content
Online content describing or depicting things of an intimate nature. Depending on cultural context, this may include nudity, parts of the body not generally exposed in public, sexually explicit material, or depictions of sex acts. May also include offensive, graphic, or violent content, or association with content or commerce involving gambling, sex, medical procedures, or recreational drug use

## Farming
Content farming involves creating online content for the sole or primary purpose of attracting page views and increasing advertising revenue, rather than out of a desire to express or communicate any particular message.

## Glorification-of-Violence
Statements or images that celebrate past or hypothetical future acts of violence.

## Hate-Speech
Abusive, hateful, or threatening content or conduct that expresses prejudice against a group or a person due to membership in a group, which may be based on legally protected characteristics, such as religion, ethnicity, nationality, race, gender identification, sexual orientation, or other characteristics. 

## Impersonation
Online impersonation most often involves the creation of an account profile that uses someone else’s name, image, likeness or other characteristics without that person’s permission to create a false or misleading impression that the account is controlled by them.

## Incitement
To encourage violence or violent sentiment against a person or group.

## Misinformation
False information that is spread unintentionally and usually not maliciously, which may nonetheless mislead or increase likelihood of harm to persons.

## NCII
Non-Consensual Intimate Imagery - Non-consensual image sharing, or non-consensual intimate image sharing (also called “non-consensual explicit imagery” or colloquially called “revenge porn”), refers to the act or threat of creating, publishing or sharing an intimate image or video without the consent of the individuals visible in it. What constitutes an intimate image will vary by cultural context. This could include nudity, private activity of various kinds, or showing someone without attire of religious or cultural significance the person would normally wear in public. The imagery may have been created by or with the consent of the individuals shown, such as in the context of an intimate relationship, or created without consent through the use of hidden cameras or other surveillance methods. Similarly, it may have been obtained with or without consent to possess it, or consent to possess it may have been revoked. It should be noted that non-consensual intimate imagery is distinct from the unlicensed sharing of copyrighted, commercially-produced adult
content.

## Online Harassment
Unsolicited repeated behavior against another person, usually with the intent to intimidate or cause emotional distress. Online harassment may take the form of one abuser targeting a person or group with sustained negative contact, or it may take the form of many
distinct individuals targeting an individual or group.

## Phishing
The fraudulent practice of sending emails or other messages purporting to be from reputable sources in order to induce individuals to reveal personal information, such as passwords and credit card numbers.

## Sock-Puppets
Multiple, fake accounts used to create an illusion of consensus or popularity, such as by liking or reposting content in order to amplify it.

## Service Abuse
Use of a product or service in a way that violates the provider’s terms of service, community guidelines, or other rules, generally because it creates or increases the risk of harm to a person or group or tends to undermine the purpose, function or quality of the service. 

## Sextortion
Where a perpetrator threatens to expose sexually compromising information (such as sexually explicit private images or videos of the victim) unless the victim meets certain demands.

## Spam
Unsolicited, low-quality communications, often (but not necessarily) high-volume commercial solicitations, sent through a range of electronic media, including email, messaging, and social media.

## Synthetic-Media
Content which has been generated or manipulated to appear as though based on reality, when it is in fact artificial. Also referred to as manipulated media. Synthetic media may sometimes (but not always) be generated through
algorithmic processes (such as artificial intelligence or machine learning). A deepfake is a form of synthetic media where an image or recording is altered to misrepresent someone doing or saying something that was not done or said.

## Troll
A user who intentionally provokes hostility or confusion online. A troll may make valid points, but generally does so with the intention to irritate.

## TVEC
Terrorist and Other Violent Extremist Content - Content produced by or supportive of groups that identify as, or have been designated as terrorist or violent organizations, or content that promotes acts of terrorism or violent extremism.

## Violent-Threat
A statement or other communication that expresses an intent to inflict physical harm on a person or a group of people. Violent threats may be direct, such as threats to kill or maim another person; they may also be indirectly implied through metaphor, analogy or other rhetoric that allows the speaker plausible deniability about their meaning or intent.

ref: https://dtspartnership.org/wp-content/uploads/2023/07/DTSP_Trust-Safety-Glossary_July-2023.pdf
