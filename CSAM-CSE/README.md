# CSAM and CSE Resources
If you suspect a child is in immediate danger in any way, contact the police immediately.

## General Guidance
 - User Generated Content and the Fediverse: A Legal Primer: https://www.eff.org/deeplinks/2022/12/user-generated-content-and-fediverse-legal-primer
 - Notes on operating fediverse services (Mastodon, Pleroma etc) from an English law point of view: https://decoded.legal/blog/2022/11/notes-on-operating-fediverse-services-mastodon-pleroma-etc-from-an-english-law-point-of-view
 - Scaling a public Mastodon instance: Legal, compliance, privacy and more: https://bottomlinelawgroup.com/2023/01/23/mastodon-instance-legal-compliance-privacy/?doing_wp_cron=1691167165.0044350624084472656250
 - Combating child sexual abuse online: https://www.europarl.europa.eu/RegData/etudes/BRIE/2022/738224/EPRS_BRI(2022)738224_EN.pdf

## Legal status of fictional pornography depicting minors
There is much confusion surrounding the legality of fictional CSAM in some territories. Regardless of its legality in a given jurisdiction, if your content is available to end users in a jurisdiction where such content is illegal, you are liable for its availability. 
 - https://en.wikipedia.org/wiki/Legal_status_of_fictional_pornography_depicting_minors

## National and Extranational Law
Scroll down to review the legality of real/realistic; fictional; and possession in most countries.
 - https://en.wikipedia.org/wiki/Legality_of_child_pornography

## Detection
Services exist to compare stored media with hashes of known material, and ML-assisted perceptual matches. For the most part, these are heavily restricted and will require your ability to sign legal agreements with the service providers. 

If you are an independent provider and would like to use IFTAS detection services, please fill out this Needs Assessment: https://cryptpad.fr/form/#/2/form/view/thnEBypiNlR6qklaQNmWAkoxxeEEJdElpzM7h2ZIwXA/ 

### CDN
 - Cloudflare CSAM Scanning Tool: https://developers.cloudflare.com/cache/reference/csam-scanning/

### Standalone Platforms
 - Microsoft PhotoDNA: https://www.microsoft.com/en-us/photodna
 - Thorn Safer: https://get.safer.io/csam-detection-tool-for-child-safety
 - Project Arachnid Shield: https://projectarachnid.ca/en/#shield
 - AI Horde csam_checker: https://github.com/Haidra-Org/horde-safety/blob/main/horde_safety/csam_checker.py

### Platform-specific
  - (Lemmy) A script that goes through a lemmy pict-rs object storage and tries to prevent illegal or unethical content: https://github.com/db0/lemmy-safety
  - (Firefish) CloudFlare configuration: https://socialweb.coop/blog/firefish-cloudflare-quickfix-r2-tutorial/

## Reporting
You may be legally required to report CSAM and/or CSE to the authorities. In general, your country of operation is what matters, followed by the country in which you host the media.

US Reporting Requirements: https://www.law.cornell.edu/uscode/text/18/2258A

List of national reporting hotlines: https://support.google.com/websearch/answer/148666?hl=en

If you can't find your country listed, contact INHOPE through their website: https://inhope.org/

## Coping with Exposure
 - Content Moderatorsâ€™ Strategies for Coping with the Stress of Moderating Content Online: https://tsjournal.org/index.php/jots/article/view/91
 - Coping with Child Sexual Abuse Material Exposure: https://www.nctsn.org/resources/coping-with-child-sexual-abuse-material-exposure

## Moderation Workflow Aids
 - Painless Peek - a browser extension to make it easier to more safley view traumatic imagery: https://github.com/adacable/painlessPeek
 - Firefox Grayscale - renders images in grayscale to reduce trauma: https://github.com/xpmn/firefox-grayscale

## Research
Child Safety on Federated Social Media: https://purl.stanford.edu/vb515nd6874

## Discussion
 - ActivityPub SocialHub: https://socialhub.activitypub.rocks/t/about-child-safety-on-federated-social-media/3447 
 - ActivityPub FEP WIP: PhotoDNA Attestation extension: https://codeberg.org/fediverse/fep/pulls/140
 - ActivityPub 2023-08-04 Special Topic Call - Social Web and CSAM: Liabilities and Tooling: https://socialhub.activitypub.rocks/t/2023-08-04-special-topic-call-social-web-and-csam-liabilities-and-tooling/3469

